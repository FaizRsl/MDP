{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrsaDfdVHzxt"
   },
   "source": [
    "# MDP - Training with YOLOv5\n",
    "\n",
    "This notebook is just a summarized, unbranded version of the one provided by [Ultralytics](https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNveqeA1KXGy"
   },
   "source": [
    "# Step 1: Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kTvDNSILZoN9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 15997, done.\u001b[K\n",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
      "remote: Total 15997 (delta 19), reused 19 (delta 12), pack-reused 15967\u001b[K\n",
      "Receiving objects: 100% (15997/15997), 14.65 MiB | 8.51 MiB/s, done.\n",
      "Resolving deltas: 100% (10985/10985), done.\n",
      "/Users/raghavrnair/Documents/GitHub/MDP/imagerec/Notebooks/Model Training Notebooks/yolov5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Setup complete. Using torch 2.0.1 (CPU)\n"
     ]
    }
   ],
   "source": [
    "#clone YOLOv5 and \n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt # install dependencies\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/raghavrnair/Documents/GitHub/MDP/imagerec/Notebooks/Model Training Notebooks/yolov5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zP6USLgz2f0r"
   },
   "source": [
    "# Step 2: Assemble Our Dataset\n",
    "\n",
    "In order to train our custom model, we need to assemble a dataset of representative images with bounding box annotations around the objects that we want to detect. And we need our dataset to be in YOLOv5 format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jjT5uIHo6l5"
   },
   "outputs": [],
   "source": [
    "# set up environment\n",
    "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZUg_Enn1dxc",
    "outputId": "109fdc67-3746-4f87-9c51-625c4f0c300a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-9bqAZsKoQ9"
   },
   "source": [
    "Copy over the pretrained model if any, to use as the starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7hSiABY1mX7"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/YOLOv5_FullPretraining.pt\" \"best.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYrPwOAmKr--"
   },
   "source": [
    "Copy over the dataset and extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7DDRxnj1sFe"
   },
   "outputs": [],
   "source": [
    "!cp \"/content/drive/MyDrive/Week8.zip\" \"Week8.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OophzbZd1tmx"
   },
   "outputs": [],
   "source": [
    "!unzip -q Week8.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7yAi9hd-T4B"
   },
   "source": [
    "# Step 3: Train Our Custom YOLOv5 model\n",
    "\n",
    "Here, we are able to pass a number of arguments:\n",
    "- **img:** define input image size\n",
    "- **batch:** determine batch size\n",
    "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
    "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
    "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
    "- **cache:** cache images for faster training\n",
    "- **hyp:** hyperparameters to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0aoEH4Ct2jbs",
    "outputId": "9b15222d-c0ae-4217-f48c-83eb76e919fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 15 06:29:01 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   31C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9SQ0s0EJ97g"
   },
   "source": [
    "Here, run `!python train.py --img 416 --batch 128 --epochs 150 --data Week8/datav5.yaml --weights best.pt --cache` first, then get the `hyp.yaml` and set flip_lr to 0, as we do not want to flip horizontally to not confuse the left and right arrows. Then, place the `hyp.yaml` back into the appropriate location and execute the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaFNnxLJbq4J"
   },
   "outputs": [],
   "source": [
    "!python train.py --img 416 --batch 128 --epochs 100 --data Week8/datav5.yaml --weights best.pt --cache --hyp hyp.yaml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtmS7_TXFsT3"
   },
   "source": [
    "#Run Inference  With Trained Weights\n",
    "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TWjjiBcic3Vz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/Users/raghavrnair/Documents/GitHub/MDP/imagerec/Weights/Week_8.pt'], source=/Users/raghavrnair/Documents/GitHub/MDP/imagerec/images/test_img.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "fatal: cannot change to '/Users/raghavrnair/Documents/GitHub/MDP/imagerec/Notebooks/Model': No such file or directory\n",
      "YOLOv5 ðŸš€ 2023-9-28 Python-3.8.18 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7093732 parameters, 0 gradients, 16.0 GFLOPs\n",
      "image 1/1 /Users/raghavrnair/Documents/GitHub/MDP/imagerec/images/test_img.jpg: 416x320 1 One, 143.8ms\n",
      "Speed: 0.7ms pre-process, 143.8ms inference, 3.2ms NMS per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights /Users/raghavrnair/Documents/GitHub/MDP/imagerec/Weights/Week_8.pt --img 416 --conf 0.1 --source /Users/raghavrnair/Documents/GitHub/MDP/imagerec/images/test_img.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "7iiObB2WCMh6",
    "outputId": "5c2c1e8a-a857-4284-d627-42f99724c9e8"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_bd6fc902-d327-4332-bf86-0f81058a7d7f\", \"best.pt\", 14358689)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export your model's weights for future use\n",
    "from google.colab import files\n",
    "files.download('./runs/train/exp/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNn-obvOGITm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
